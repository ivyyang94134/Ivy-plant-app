import { GoogleGenerativeAI } from "@google/generative-ai";

export const config = {
    runtime: 'edge', // Use Edge Runtime for faster cold boots
};

export default async function handler(req) {
    // CORS headers for allowing requests from your Vercel app
    const headers = {
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'OPTIONS, POST',
        'Access-Control-Allow-Headers': 'Content-Type',
        'Content-Type': 'application/json',
    };

    // Handle preflight requests
    if (req.method === 'OPTIONS') {
        return new Response(null, { headers });
    }

    if (req.method !== 'POST') {
        return new Response(JSON.stringify({ error: 'Method not allowed' }), {
            status: 405,
            headers,
        });
    }

    try {
        const { imageBase64 } = await req.json();

        if (!imageBase64) {
            throw new Error('No image data provided');
        }

        const API_KEY = process.env.VITE_GEMINI_API_KEY;
        if (!API_KEY) {
            console.error("Server Key Missing");
            throw new Error('Server configuration error: API Key missing');
        }

        const genAI = new GoogleGenerativeAI(API_KEY);

        // Helper to run a model
        const runModel = async (modelName) => {
            console.log(`[Proxy] Trying model: ${modelName}`);
            const model = genAI.getGenerativeModel({ model: modelName });

            const prompt = `
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ¤ç‰©å­¸å®¶èˆ‡é¢¨æ°´å°ˆå®¶ã€‚è«‹åˆ†æé€™å¼µæ¤ç‰©åœ–ç‰‡ï¼Œä¸¦å›å‚³ä»¥ä¸‹ JSON æ ¼å¼çš„è³‡è¨Š (ç¹é«”ä¸­æ–‡)ï¼š
            {
                "id": "generated_id",
                "name": "æ¤ç‰©åç¨± (å­¸å)",
                "confidence": 95,
                "description": "2-3å¥è©±çš„æ¤ç‰©ä»‹ç´¹ã€‚",
                "safety": "è«‹èªªæ˜æ˜¯å¦æœ‰æ¯’ (ä¾‹å¦‚ï¼šâš ï¸ æœ‰æ¯’... æˆ– âœ… å®‰å…¨... )",
                "fengShui": "è«‹èªªæ˜é¢¨æ°´å¯“æ„ (ä¾‹å¦‚ï¼šğŸŒŸ é¢¨æ°´åˆ†æ... )ï¼Œè‹¥ä¸ç¢ºå®šå‰‡å›å‚³ null",
                "health": {
                "status": "healthy" æˆ– "sick",
                "title": "å¥åº·ç‹€æ…‹æ¨™é¡Œ",
                "summary": "å¥åº·ç‹€æ³ç°¡è¿°",
                "tips": "1-2 é»è­·ç†å»ºè­°"
                }
            }
            è«‹ç¢ºä¿å›å‚³çš„æ˜¯ç´” JSON å­—ä¸²ï¼Œä¸è¦æœ‰ markdown code block æ¨™è¨˜ã€‚`;

            const result = await model.generateContent([
                prompt,
                {
                    inlineData: {
                        data: imageBase64,
                        mimeType: "image/jpeg",
                    },
                },
            ]);

            const response = await result.response;
            const text = response.text();
            const cleanText = text.replace(/```json/g, '').replace(/```/g, '').trim();
            return JSON.parse(cleanText);
        };

        // Try models in sequence
        const models = ["gemini-2.0-flash", "gemini-2.0-flash-lite", "gemini-1.5-flash"];
        let lastError = null;

        for (const model of models) {
            try {
                const data = await runModel(model);
                return new Response(JSON.stringify(data), { headers });
            } catch (err) {
                console.warn(`[Proxy] Model ${model} failed:`, err.message);
                lastError = err;
                // If 429/503 we might want to continue, but if Key invalid, stop?
                // For simplicity, just try next.
            }
        }

        throw lastError || new Error("All models failed");

    } catch (error) {
        console.error("[Proxy] Error:", error);
        return new Response(JSON.stringify({
            error: error.message,
            details: error.toString()
        }), {
            status: 500,
            headers,
        });
    }
}
